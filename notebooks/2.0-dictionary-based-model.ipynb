{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with dictionary based model\n",
    "\n",
    "The idea behind this model is very simple. I will build a dictionary of toxic words with their replacement words in the format: `{<toxic_word>: <neutral_word>}`. I want to preserve the context of the words, but I am not sure it will be working well. To build it, I would filter the given data to take only most similar texts in terms of cosine distance and length. Additionally, to add some pair to the dictionary I am planning to double check the words via simple toxicity classifier provided by HuggingFace library, namely, [`s-nlp/roberta-toxicity-classifier`](https://huggingface.co/s-nlp/roberta_toxicity_classifier). Selected classifier is developed by \"s-nlp\" team (referenced in the assignment description) and it used fine-tuned Transformer-based model (RoBERTa), which achieved state-of-the-art results at some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maine was very short on black people back then.</td>\n",
       "      <td>there wasn't much black in Maine then.</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.148710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Briggs, what the hell's happening?</td>\n",
       "      <td>Briggs, what the hell is going on?</td>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159096</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Another one simply had no clue what to do, so ...</td>\n",
       "      <td>another simply didn't know what to do, so when...</td>\n",
       "      <td>0.877540</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.055371</td>\n",
       "      <td>0.930472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I suppose you want me to buy you flowers and c...</td>\n",
       "      <td>you'd probably want me to buy you some chocola...</td>\n",
       "      <td>0.800661</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.980341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So now their spirits are cursed, walking back ...</td>\n",
       "      <td>their souls are cursed, they guard the paths, ...</td>\n",
       "      <td>0.755883</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.842509</td>\n",
       "      <td>0.143992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Freezing him.</td>\n",
       "      <td>I'll freeze him!</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.573710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Come on, Cal, leave that shit alone.</td>\n",
       "      <td>come on, Cal, put it down.</td>\n",
       "      <td>0.660481</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>So he's the Top dog.</td>\n",
       "      <td>he's the tallest son of a bitch.</td>\n",
       "      <td>0.611092</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.999639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reference  \\\n",
       "0   If Alkar is flooding her with psychic waste, t...   \n",
       "1                           Now you're getting nasty.   \n",
       "2            Well, we could spare your life, for one.   \n",
       "3           Ah! Monkey, you've got to snap out of it.   \n",
       "4                    I've got orders to put her down.   \n",
       "5   I'm not gonna have a child... ...with the same...   \n",
       "6   They're all laughing at us, so we'll kick your...   \n",
       "7     Maine was very short on black people back then.   \n",
       "8                  Briggs, what the hell's happening?   \n",
       "9   Another one simply had no clue what to do, so ...   \n",
       "10  I suppose you want me to buy you flowers and c...   \n",
       "11  So now their spirits are cursed, walking back ...   \n",
       "12                                      Freezing him.   \n",
       "13               Come on, Cal, leave that shit alone.   \n",
       "14                               So he's the Top dog.   \n",
       "\n",
       "                                          translation  similarity  \\\n",
       "0   if Alkar floods her with her mental waste, it ...    0.785171   \n",
       "1                         you're becoming disgusting.    0.749687   \n",
       "2                       well, we can spare your life.    0.919051   \n",
       "3                        monkey, you have to wake up.    0.664333   \n",
       "4                          I have orders to kill her.    0.726639   \n",
       "5   I'm not going to breed kids with a genetic dis...    0.703185   \n",
       "6             they're laughing at us. We'll show you.    0.618866   \n",
       "7              there wasn't much black in Maine then.    0.720482   \n",
       "8                  Briggs, what the hell is going on?    0.920373   \n",
       "9   another simply didn't know what to do, so when...    0.877540   \n",
       "10  you'd probably want me to buy you some chocola...    0.800661   \n",
       "11  their souls are cursed, they guard the paths, ...    0.755883   \n",
       "12                                   I'll freeze him!    0.775646   \n",
       "13                         come on, Cal, put it down.    0.660481   \n",
       "14                   he's the tallest son of a bitch.    0.611092   \n",
       "\n",
       "    lenght_diff   ref_tox   trn_tox  \n",
       "0      0.010309  0.014195  0.981983  \n",
       "1      0.071429  0.065473  0.999039  \n",
       "2      0.268293  0.213313  0.985068  \n",
       "3      0.309524  0.053362  0.994215  \n",
       "4      0.181818  0.009402  0.999348  \n",
       "5      0.206522  0.950956  0.035846  \n",
       "6      0.230769  0.999492  0.000131  \n",
       "7      0.187500  0.963680  0.148710  \n",
       "8      0.000000  0.159096  0.841071  \n",
       "9      0.101695  0.055371  0.930472  \n",
       "10     0.160000  0.000078  0.980341  \n",
       "11     0.013245  0.842509  0.143992  \n",
       "12     0.176471  0.007186  0.573710  \n",
       "13     0.270270  0.999637  0.000279  \n",
       "14     0.363636  0.000920  0.999639  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# The data should be downloaded, use 1.0-download-raw-data.ipynb notebook\n",
    "raw_data_path = '../data/raw/filtered.tsv'\n",
    "df = pd.read_csv(raw_data_path, sep='\\t', index_col=0)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore number of samples filtering by length difference and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Briggs, what the hell's happening?</td>\n",
       "      <td>Briggs, what the hell is going on?</td>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159096</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I'm famous, and you're done.</td>\n",
       "      <td>I'm famous, and you're dead.</td>\n",
       "      <td>0.817253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.979738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Murder for hire.</td>\n",
       "      <td>murder to order.</td>\n",
       "      <td>0.697667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074589</td>\n",
       "      <td>0.962326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>As long as you work for these goombahs, you're...</td>\n",
       "      <td>as long as you work for these patrons, you're ...</td>\n",
       "      <td>0.770949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.998543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>What the heck was that all about?</td>\n",
       "      <td>what the fuck was that all about?</td>\n",
       "      <td>0.915779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.998830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577667</th>\n",
       "      <td>And quit shooting up the lawn sign.</td>\n",
       "      <td>and stop shooting at the damn sign.</td>\n",
       "      <td>0.723342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013603</td>\n",
       "      <td>0.999410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577692</th>\n",
       "      <td>I was just telling Nina about the \"hooked and ...</td>\n",
       "      <td>I was just telling Nina about the \"caught and ...</td>\n",
       "      <td>0.823564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.991810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577712</th>\n",
       "      <td>You think Hal's banging her?</td>\n",
       "      <td>you think Hal's fucking her?</td>\n",
       "      <td>0.908113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.998315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577738</th>\n",
       "      <td>We're all doommed.</td>\n",
       "      <td>we are all cursed!</td>\n",
       "      <td>0.611297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.844721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577754</th>\n",
       "      <td>Xar knew Bane for what he wasa skilled and cun...</td>\n",
       "      <td>Xar knew what Bane was, a cunning and cunning ...</td>\n",
       "      <td>0.859017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050859</td>\n",
       "      <td>0.951482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28514 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference  \\\n",
       "8                      Briggs, what the hell's happening?   \n",
       "16                           I'm famous, and you're done.   \n",
       "19                                       Murder for hire.   \n",
       "47      As long as you work for these goombahs, you're...   \n",
       "88                      What the heck was that all about?   \n",
       "...                                                   ...   \n",
       "577667                And quit shooting up the lawn sign.   \n",
       "577692  I was just telling Nina about the \"hooked and ...   \n",
       "577712                       You think Hal's banging her?   \n",
       "577738                                 We're all doommed.   \n",
       "577754  Xar knew Bane for what he wasa skilled and cun...   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "8                      Briggs, what the hell is going on?    0.920373   \n",
       "16                           I'm famous, and you're dead.    0.817253   \n",
       "19                                       murder to order.    0.697667   \n",
       "47      as long as you work for these patrons, you're ...    0.770949   \n",
       "88                      what the fuck was that all about?    0.915779   \n",
       "...                                                   ...         ...   \n",
       "577667                and stop shooting at the damn sign.    0.723342   \n",
       "577692  I was just telling Nina about the \"caught and ...    0.823564   \n",
       "577712                       you think Hal's fucking her?    0.908113   \n",
       "577738                                 we are all cursed!    0.611297   \n",
       "577754  Xar knew what Bane was, a cunning and cunning ...    0.859017   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "8               0.0  0.159096  0.841071  \n",
       "16              0.0  0.000926  0.979738  \n",
       "19              0.0  0.074589  0.962326  \n",
       "47              0.0  0.018583  0.998543  \n",
       "88              0.0  0.027907  0.998830  \n",
       "...             ...       ...       ...  \n",
       "577667          0.0  0.013603  0.999410  \n",
       "577692          0.0  0.000053  0.991810  \n",
       "577712          0.0  0.000241  0.998315  \n",
       "577738          0.0  0.001918  0.844721  \n",
       "577754          0.0  0.050859  0.951482  \n",
       "\n",
       "[28514 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.lenght_diff == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Calm down, the more you cry out, the faster yo...</td>\n",
       "      <td>calm down, the more you scream, the faster you...</td>\n",
       "      <td>0.943573</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.038697</td>\n",
       "      <td>0.588769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>But this is absurd!</td>\n",
       "      <td>but this is ridiculous!</td>\n",
       "      <td>0.940884</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.981858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>The greedy and the selfish.</td>\n",
       "      <td>greedy and selfish.</td>\n",
       "      <td>0.948259</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.990820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>A Revolutionary would already put a bullet in ...</td>\n",
       "      <td>a revolutionary would put a bullet in my head ...</td>\n",
       "      <td>0.944253</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.174924</td>\n",
       "      <td>0.966754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>What were we supposed to do?</td>\n",
       "      <td>what the hell were we supposed to do?</td>\n",
       "      <td>0.944460</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.723566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577493</th>\n",
       "      <td>They're the rats of the sea.</td>\n",
       "      <td>it's the rats of the sea.</td>\n",
       "      <td>0.949521</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.996255</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577522</th>\n",
       "      <td>If bin Laden would be caught or killed right now,</td>\n",
       "      <td>if Bin Laden was caught or killed now,</td>\n",
       "      <td>0.948106</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.643583</td>\n",
       "      <td>0.011261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577560</th>\n",
       "      <td>It's silly of me, but I'm afraid of them... an...</td>\n",
       "      <td>it's stupid of me, but I'm scared of them........</td>\n",
       "      <td>0.946580</td>\n",
       "      <td>0.087379</td>\n",
       "      <td>0.088424</td>\n",
       "      <td>0.994271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577687</th>\n",
       "      <td>Have you ever... seen breasts?</td>\n",
       "      <td>have you ever seen boobs?</td>\n",
       "      <td>0.945825</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.941499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577743</th>\n",
       "      <td>I'm black! And we like fried chicken.</td>\n",
       "      <td>I'm black and we want fried chicken!</td>\n",
       "      <td>0.943591</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.087164</td>\n",
       "      <td>0.778933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7509 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference  \\\n",
       "161     Calm down, the more you cry out, the faster yo...   \n",
       "203                                   But this is absurd!   \n",
       "240                           The greedy and the selfish.   \n",
       "343     A Revolutionary would already put a bullet in ...   \n",
       "376                          What were we supposed to do?   \n",
       "...                                                   ...   \n",
       "577493                       They're the rats of the sea.   \n",
       "577522  If bin Laden would be caught or killed right now,   \n",
       "577560  It's silly of me, but I'm afraid of them... an...   \n",
       "577687                     Have you ever... seen breasts?   \n",
       "577743              I'm black! And we like fried chicken.   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "161     calm down, the more you scream, the faster you...    0.943573   \n",
       "203                               but this is ridiculous!    0.940884   \n",
       "240                                   greedy and selfish.    0.948259   \n",
       "343     a revolutionary would put a bullet in my head ...    0.944253   \n",
       "376                 what the hell were we supposed to do?    0.944460   \n",
       "...                                                   ...         ...   \n",
       "577493                          it's the rats of the sea.    0.949521   \n",
       "577522             if Bin Laden was caught or killed now,    0.948106   \n",
       "577560  it's stupid of me, but I'm scared of them........    0.946580   \n",
       "577687                          have you ever seen boobs?    0.945825   \n",
       "577743               I'm black and we want fried chicken!    0.943591   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "161        0.068966  0.038697  0.588769  \n",
       "203        0.166667  0.004456  0.981858  \n",
       "240        0.285714  0.007085  0.990820  \n",
       "343        0.125000  0.174924  0.966754  \n",
       "376        0.236842  0.000045  0.723566  \n",
       "...             ...       ...       ...  \n",
       "577493     0.103448  0.996255  0.021550  \n",
       "577522     0.220000  0.643583  0.011261  \n",
       "577560     0.087379  0.088424  0.994271  \n",
       "577687     0.161290  0.165173  0.941499  \n",
       "577743     0.026316  0.087164  0.778933  \n",
       "\n",
       "[7509 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.similarity > 0.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Briggs, what the hell's happening?</td>\n",
       "      <td>Briggs, what the hell is going on?</td>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159096</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I think you are the strangest man I've ever met.</td>\n",
       "      <td>I think you're the weirdest person I've ever met.</td>\n",
       "      <td>0.934353</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.962527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The reward on his head is substantial.</td>\n",
       "      <td>there is considerable reward for his head.</td>\n",
       "      <td>0.908223</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.035881</td>\n",
       "      <td>0.910780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I swear to God, the best thing I ever did in m...</td>\n",
       "      <td>I swear to God, the best thing I've ever done ...</td>\n",
       "      <td>0.932305</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.999071</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>What the heck was that all about?</td>\n",
       "      <td>what the fuck was that all about?</td>\n",
       "      <td>0.915779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.998830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577576</th>\n",
       "      <td>Your car is going to flip, shattering your spi...</td>\n",
       "      <td>your car's gonna flip, you'll crush the spinal...</td>\n",
       "      <td>0.915279</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.766299</td>\n",
       "      <td>0.117041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577663</th>\n",
       "      <td>Excuse me! Clown?</td>\n",
       "      <td>excuse me, clown?</td>\n",
       "      <td>0.939452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.993706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577703</th>\n",
       "      <td>You're a vulture Corso!</td>\n",
       "      <td>you're a vulture, Corso.</td>\n",
       "      <td>0.900430</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.171164</td>\n",
       "      <td>0.920206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577712</th>\n",
       "      <td>You think Hal's banging her?</td>\n",
       "      <td>you think Hal's fucking her?</td>\n",
       "      <td>0.908113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.998315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577743</th>\n",
       "      <td>I'm black! And we like fried chicken.</td>\n",
       "      <td>I'm black and we want fried chicken!</td>\n",
       "      <td>0.943591</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.087164</td>\n",
       "      <td>0.778933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19756 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference  \\\n",
       "8                      Briggs, what the hell's happening?   \n",
       "23       I think you are the strangest man I've ever met.   \n",
       "39                 The reward on his head is substantial.   \n",
       "43      I swear to God, the best thing I ever did in m...   \n",
       "88                      What the heck was that all about?   \n",
       "...                                                   ...   \n",
       "577576  Your car is going to flip, shattering your spi...   \n",
       "577663                                  Excuse me! Clown?   \n",
       "577703                            You're a vulture Corso!   \n",
       "577712                       You think Hal's banging her?   \n",
       "577743              I'm black! And we like fried chicken.   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "8                      Briggs, what the hell is going on?    0.920373   \n",
       "23      I think you're the weirdest person I've ever met.    0.934353   \n",
       "39             there is considerable reward for his head.    0.908223   \n",
       "43      I swear to God, the best thing I've ever done ...    0.932305   \n",
       "88                      what the fuck was that all about?    0.915779   \n",
       "...                                                   ...         ...   \n",
       "577576  your car's gonna flip, you'll crush the spinal...    0.915279   \n",
       "577663                                  excuse me, clown?    0.939452   \n",
       "577703                           you're a vulture, Corso.    0.900430   \n",
       "577712                       you think Hal's fucking her?    0.908113   \n",
       "577743               I'm black and we want fried chicken!    0.943591   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "8          0.000000  0.159096  0.841071  \n",
       "23         0.020000  0.003785  0.962527  \n",
       "39         0.093023  0.035881  0.910780  \n",
       "43         0.022472  0.999071  0.000900  \n",
       "88         0.000000  0.027907  0.998830  \n",
       "...             ...       ...       ...  \n",
       "577576     0.053571  0.766299  0.117041  \n",
       "577663     0.000000  0.009608  0.993706  \n",
       "577703     0.040000  0.171164  0.920206  \n",
       "577712     0.000000  0.000241  0.998315  \n",
       "577743     0.026316  0.087164  0.778933  \n",
       "\n",
       "[19756 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.lenght_diff < 0.1) & (df.similarity > 0.9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, having around 20k of relatively similar texts in terms of cosine distance and length, we can easier try to build dictionary of toxic words out of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing functions for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refernce: PMLDL Lab 3 notebook\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "\n",
    "def lower_text(text: str):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_numbers(text: str):\n",
    "    text_nonum = re.sub(r'\\d+', ' ', text)\n",
    "    return text_nonum\n",
    "\n",
    "def remove_punctuation(text: str):\n",
    "    text_nopunct = re.sub(r'[^a-z|\\s]+', '', text)\n",
    "    return text_nopunct\n",
    "\n",
    "def remove_multiple_spaces(text: str):\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text).strip()\n",
    "    return text_no_doublespace\n",
    "\n",
    "def remove_contracted_forms(text: str):\n",
    "    text_no_contracted_forms = re.sub(\"(\\w+)'(\\w+)\", '', text)\n",
    "    return text_no_contracted_forms\n",
    "\n",
    "def tokenize_text(text: str) -> list[str]:\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stop_words(tokenized_text: list[str]) -> list[str]:\n",
    "    return [token for token in tokenized_text if token not in stopwords.words('english')]\n",
    "    \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def stem_words(tokenized_text: list[str]) -> list[str]:\n",
    "    return [stemmer.stem(token) for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    _text = lower_text(text)\n",
    "    _text = remove_numbers(_text)\n",
    "    _text = remove_contracted_forms(_text)\n",
    "    _text = remove_punctuation(_text)\n",
    "    _text = remove_multiple_spaces(_text)\n",
    "    return _text\n",
    "\n",
    "def tokenize_and_stem(text, inference=False):\n",
    "    tokenized = tokenize_text(text)\n",
    "    if not inference:\n",
    "        tokenized = remove_stop_words(tokenized)\n",
    "        stemmed = stem_words(tokenized)\n",
    "        return tokenized, stemmed\n",
    "    else:\n",
    "        return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a text toxicity classifier from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'toxic', 'score': 0.9994775652885437}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "text_classifier = pipeline(\"text-classification\", model=\"s-nlp/roberta_toxicity_classifier\")\n",
    "result = text_classifier('stupid')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "\n",
    "The algorithm is following: iterating over filtered samples of data (1) apply text preprocessing, (2) apply text tokenization and stemming using `nltk` library, (3) skip equal word's stem in both reference and translation, (4) for other pairs of words apply text toxicity classifier, (5) if conditions on toxic and neutral pair are met, add the pair to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_dict = {}\n",
    "data_for_dict = df[(df.lenght_diff < 0.1) & (df.similarity > 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dictionary of toxic words and their replacements: 100%|██████████| 19756/19756 [1:41:12<00:00,  3.25it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for _, row in tqdm(data_for_dict.iterrows(), desc='Building dictionary of toxic words and their replacements', total=len(data_for_dict)):\n",
    "    ref_cleaned = clean(row.reference)\n",
    "    trn_cleaned = clean(row.translation)\n",
    "    ref_tokenized, ref_stemmed = tokenize_and_stem(ref_cleaned)\n",
    "    trn_tokenized, trn_stemmed = tokenize_and_stem(trn_cleaned)\n",
    "    if row.ref_tox < row.trn_tox:\n",
    "        ref_tokenized, trn_tokenized = trn_tokenized, ref_tokenized\n",
    "        ref_stemmed, trn_stemmed = trn_stemmed, ref_stemmed\n",
    "\n",
    "    for i in range(len(ref_stemmed)):\n",
    "        w = ref_stemmed[i]\n",
    "        if w in trn_stemmed:\n",
    "            j = trn_stemmed.index(w)\n",
    "            ref_tokenized[i] = None\n",
    "            trn_tokenized[j] = None\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(len(ref_tokenized)):\n",
    "        w1 = ref_tokenized[i]\n",
    "        w2 = trn_tokenized[j] if j < len(trn_tokenized) else None\n",
    "        if w1 is not None:\n",
    "            if w2 is not None:\n",
    "                # Inference of text toxicity classifier\n",
    "                w1_toxicity, w2_toxicity = text_classifier(w1), text_classifier(w2)\n",
    "                if w1 not in tox_dict and w1_toxicity[0]['label'] == 'toxic' and w2_toxicity[0]['label'] == 'neutral': \n",
    "                    tox_dict[w1] = w2\n",
    "                j += 1\n",
    "        else:\n",
    "            j += 1\n",
    "print(f'Dictionary size: {len(tox_dict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save built dictionary internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "tox_dict_dir = '../data/internal/toxic_dict.pkl' \n",
    "with open(tox_dict_dir, 'wb') as f:\n",
    "    pickle.dump(tox_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try built dictionary in action (inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load toxic dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "tox_dict_dir = '../data/internal/toxic_dict.pkl' \n",
    "with open(tox_dict_dir, 'rb') as f:\n",
    "    tox_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the same text toxicity classifier for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'toxic', 'score': 0.9996129870414734}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "text_classifier = pipeline(\"text-classification\", model=\"s-nlp/roberta_toxicity_classifier\")\n",
    "result = text_classifier('stupid bitch')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample some data close to the similarity which was used to build dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[(df.similarity > 0.8) | (df.lenght_diff < 0.2)]\n",
    "n = 50\n",
    "random_test_data = test_data.sample(n=n, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply manual testing (model inference). The idea here to replace toxic words if we found them in our dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT [{'label': 'toxic', 'score': 0.9995489716529846}]: he's a stupid, lovable kid.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9982800483703613}]: It's a clueless kid in love.\n",
      "PRED [{'label': 'neutral', 'score': 0.9994958639144897}]: he 's a linnet , lovable kid .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9943583607673645}]: This tramp is trying to tear apart our family.\n",
      "GOLD [{'label': 'neutral', 'score': 0.8928444981575012}]: the vagrant is trying to tear our family apart.\n",
      "PRED [{'label': 'toxic', 'score': 0.9942286014556885}]: This tramp is trying to tear apart our family .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9859511256217957}]: oh, crap. Excuse me.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999043941497803}]: Oh, God. Excuse me.\n",
      "PRED [{'label': 'neutral', 'score': 0.9709659814834595}]: oh , hell . Excuse me .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9915751814842224}]: that will kill him in the end: Thirst.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9907763600349426}]: That was what would kill him: his thirst.\n",
      "PRED [{'label': 'toxic', 'score': 0.9895913004875183}]: that will murder him in the end : Thirst .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9958351850509644}]: It's a unicorn with a cock inside.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9998315572738647}]: it's a unicorn with a bird inside.\n",
      "PRED [{'label': 'toxic', 'score': 0.9941313862800598}]: It 's a unicorn with a cock inside .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9332228899002075}]: We think the fire that killed him started with a butt he'd thrown down.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9992048144340515}]: we think the fire that killed him originated from an discarded non-dopamine.\n",
      "PRED [{'label': 'toxic', 'score': 0.9624581336975098}]: We think the fire that killed him started with a butt he 'd thrown down .\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.9861199855804443}]: you don't burn them with a nanny and a chicken.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9996023774147034}]: You don't bribe them with babysitters and chicken.\n",
      "PRED [{'label': 'neutral', 'score': 0.9568248391151428}]: you do n't burn them with a nanny and a chicken .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9903011322021484}]: Insolent girl!\n",
      "GOLD [{'label': 'neutral', 'score': 0.9767886400222778}]: shameless girl!\n",
      "PRED [{'label': 'toxic', 'score': 0.9905679821968079}]: Insolent girl !\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9972686767578125}]: Oh, jeez, a homicidal maniac acting totally crazy.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9890680909156799}]: oh, geez, crazy homicidal games are totally crazy.\n",
      "PRED [{'label': 'neutral', 'score': 0.7649659514427185}]: Oh , jeez , a homicidal freak acting totally gone .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9401986002922058}]: What the hell happened to you?\n",
      "GOLD [{'label': 'neutral', 'score': 0.9735670685768127}]: but what the hell happened to you?\n",
      "PRED [{'label': 'toxic', 'score': 0.9726426601409912}]: What the hell happened to you ?\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9941752552986145}]: she was cold, brutish and unpleasant.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9987252354621887}]: It was a cold, meagre and uncomfortable thing.\n",
      "PRED [{'label': 'toxic', 'score': 0.9811463356018066}]: she was cold , brutish and unpleasant .\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.9699950218200684}]: Maybe I just want to feel the warmth of her chest cavity as I rip out her heart and watch her face as she realizes I took it from her.\n",
      "GOLD [{'label': 'neutral', 'score': 0.7132471799850464}]: I just want to feel the warmth of her body when I rip her heart out of her chest while I'm watching her face when she realizes I've ripped her heart out.\n",
      "PRED [{'label': 'neutral', 'score': 0.9685760736465454}]: Maybe I just want to feel the warmth of her chest cavity as I rip out her heart and watch her face as she realizes I took it from her .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9994934797286987}]: I bet you do, you crazy bitch.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9881083369255066}]: Yeah, I bet you have, you sassy cat.\n",
      "PRED [{'label': 'neutral', 'score': 0.9999434947967529}]: I bet you do , you gone going .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.7600557208061218}]: War's given the negro the right to decide what he wants, so...\n",
      "GOLD [{'label': 'neutral', 'score': 0.83464515209198}]: the war gave the black man the right to decide what he wanted, so...\n",
      "PRED [{'label': 'toxic', 'score': 0.8046908974647522}]: War 's given the negro the right to decide what he wants , so ...\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.8591299057006836}]: Sit under him with a pail and pretend he's a cow.\n",
      "GOLD [{'label': 'neutral', 'score': 0.975002110004425}]: sit under him with a bucket and pretend it's a cow.\n",
      "PRED [{'label': 'neutral', 'score': 0.9732591509819031}]: Sit under him with a pail and pretend he 's a cow .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.99212646484375}]: What, and just let all those souls burn?\n",
      "GOLD [{'label': 'neutral', 'score': 0.9934038519859314}]: what, and keep the souls on fire?\n",
      "PRED [{'label': 'toxic', 'score': 0.9928808212280273}]: What , and just let all those souls burn ?\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.939064085483551}]: Only a little, stunted kitchen wench, which her late father left behind. But she cannot present herself.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999421834945679}]: she's just a small stint in the kitchen, which her father left behind, but she can't imagine.\n",
      "PRED [{'label': 'neutral', 'score': 0.9853052496910095}]: Only a little , stunted kitchen wench , which her late father left behind . But she can not present herself .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9970353841781616}]: Now, please... will you pinch this shit off? ...Unless... ...Oh...\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999220371246338}]: so, please, would you mind getting out of this mess?... if you don't mind...\n",
      "PRED [{'label': 'toxic', 'score': 0.7706061601638794}]: Now , please ... will you pinch this hell off ? ... Unless ... ... Oh ...\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9984586238861084}]: How come you look like crap?\n",
      "GOLD [{'label': 'toxic', 'score': 0.9602361917495728}]: why do you look so awful?\n",
      "PRED [{'label': 'toxic', 'score': 0.9628536105155945}]: How come you look like hell ?\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9340999722480774}]: shooting pilots.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9901386499404907}]: Downed pilots.\n",
      "PRED [{'label': 'toxic', 'score': 0.8999456763267517}]: shooting pilots .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9942564368247986}]: your job is to humiliate and humiliate his humanity.\n",
      "GOLD [{'label': 'neutral', 'score': 0.8877111673355103}]: Its purpose is to humiliate and degrade the human being.\n",
      "PRED [{'label': 'toxic', 'score': 0.9926853179931641}]: your job is to humiliate and humiliate his humanity .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9994031190872192}]: Then why are you working with morons?\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999586343765259}]: then why do you work with kids?\n",
      "PRED [{'label': 'toxic', 'score': 0.9993836879730225}]: Then why are you working with morons ?\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9981295466423035}]: The coffee sucks.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9690054059028625}]: coffee's lousy.\n",
      "PRED [{'label': 'neutral', 'score': 0.9998704195022583}]: The coffee bad .\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.8546159267425537}]: They were very black and totally foreign; they spoke in their African tongues, and they spoke the French patois; and when they sang, they sang African songs which made the fields exotic and strange, always frightening to me in my mortal life.\n",
      "GOLD [{'label': 'toxic', 'score': 0.7182571887969971}]: they were all black and utterly alien, they spoke African languages, and they were French, and when they got into singing, they sang African songs, which gave work to the fields of a strange exoticism, and for my deathly my own mortality.\n",
      "PRED [{'label': 'neutral', 'score': 0.9993844032287598}]: They were very could and totally foreign ; they spoke in their African tongues , and they spoke the French patois ; and when they sang , they sang African songs which made the fields exotic and strange , always frightening to me in my mortal life .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9858207702636719}]: Fort Hamilton, class of 1992, and a funny dick.\n",
      "GOLD [{'label': 'toxic', 'score': 0.8931663632392883}]: Fort Hamilton, class of '92 and a funny prick.\n",
      "PRED [{'label': 'neutral', 'score': 0.9902315735816956}]: Fort Hamilton , class of 1992 , and a funny douche .\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.9988114833831787}]: I'm doing my job, and she just shoots me down in front of everybody.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999616146087646}]: I'm doing my job, and she's just dropping me off in front of everyone.\n",
      "PRED [{'label': 'neutral', 'score': 0.9984556436538696}]: I 'm doing my job , and she just shoots me down in front of everybody .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9928092956542969}]: I had this coffin built to catch those useless Alchemists.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9954966306686401}]: I had this coffin built to catch an unusable Alchemist.\n",
      "PRED [{'label': 'neutral', 'score': 0.9824513792991638}]: I had this coffin built to catch those point Alchemists .\n",
      "\n",
      "INIT [{'label': 'neutral', 'score': 0.9488743543624878}]: Clean up that pigsty of a room.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9998347759246826}]: clean up the mess in the room.\n",
      "PRED [{'label': 'neutral', 'score': 0.9839776158332825}]: Clean up that sty of a room .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9953863024711609}]: \"are you crazy?\n",
      "GOLD [{'label': 'neutral', 'score': 0.9847153425216675}]: \"Are you mad?\n",
      "PRED [{'label': 'neutral', 'score': 0.9996063113212585}]: `` are you gone ?\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.96142578125}]: stop complaining and act like a baby.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9906746745109558}]: Oh, stop crying and don't be big baby.\n",
      "PRED [{'label': 'toxic', 'score': 0.9386727809906006}]: stop complaining and act like a baby .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.8511317372322083}]: you shoot the gun out of the gun and you wake up all the neighbors.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9304744005203247}]: You fire that gun, and the whole neighborhood is gonna hear you.\n",
      "PRED [{'label': 'neutral', 'score': 0.9983077049255371}]: you make the gun out of the gun and you wake up all the neighbors .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9691539406776428}]: Yeah, but that's ridiculous.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999574422836304}]: yeah, but that's exaggerated.\n",
      "PRED [{'label': 'neutral', 'score': 0.9918140172958374}]: Yeah , but that 's laughable .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9869938492774963}]: \"Rise up, nigger,\" he said softly.\n",
      "GOLD [{'label': 'toxic', 'score': 0.9689642190933228}]: \"jaws up, black mouth,\" he said softly.\n",
      "PRED [{'label': 'toxic', 'score': 0.9671033620834351}]: `` Rise up , nigga , '' he said softly .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.990053653717041}]: So there I was... ...at the mercy of three monstrous trolls.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9898262023925781}]: and so I was... at the mercy of three awful bad men.\n",
      "PRED [{'label': 'toxic', 'score': 0.9920152425765991}]: So there I was ... ... at the mercy of three monstrous trolls .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9924191236495972}]: He wants to be there for me with all this shit happening.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999637603759766}]: he wants to be there for me because he knows what I'm going through.\n",
      "PRED [{'label': 'neutral', 'score': 0.9991850256919861}]: He wants to be there for me with all this hell happening .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9807784557342529}]: And so he was an ugly man, this Faethor Ferenczy.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9668375849723816}]: he was an unpleasant man, this Faethor Ferenczy.\n",
      "PRED [{'label': 'neutral', 'score': 0.9900334477424622}]: And so he was an bad man , this Faethor Ferenczy .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9672138690948486}]: If you were a Nazi, after the war... and if you were a vampire... and if you were a Nazi vampire...\n",
      "GOLD [{'label': 'toxic', 'score': 0.9318809509277344}]: but when you were after the war...... and a vampire...... and when you were a Nazi vampire...\n",
      "PRED [{'label': 'toxic', 'score': 0.9817649126052856}]: If you were a Nazi , after the war ... and if you were a vampire ... and if you were a Nazi vampire ...\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9911399483680725}]: I won't impose my presence after all the shit I caused.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999364614486694}]: after all, I don't want to bother you with my presence.\n",
      "PRED [{'label': 'neutral', 'score': 0.9889040589332581}]: I wo n't impose my presence after all the hell I caused .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9975751042366028}]: all we know is they can all be dead.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9970213770866394}]: For all we know, everyone could be dead.\n",
      "PRED [{'label': 'toxic', 'score': 0.9973922967910767}]: all we know is they can all be dead .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9986850619316101}]: That's fucking disgusting.\n",
      "GOLD [{'label': 'toxic', 'score': 0.6617571711540222}]: that's disgusting.\n",
      "PRED [{'label': 'neutral', 'score': 0.9852584004402161}]: That 's freakin horrible .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.8950628638267517}]: he really is crazy, right?\n",
      "GOLD [{'label': 'neutral', 'score': 0.9520930051803589}]: He's real twisted up, ain't he?\n",
      "PRED [{'label': 'neutral', 'score': 0.999922513961792}]: he really is gone , right ?\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9837085604667664}]: he looks... crazy.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9264694452285767}]: He looks... crazed.\n",
      "PRED [{'label': 'neutral', 'score': 0.9999406337738037}]: he looks ... gone .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9437236189842224}]: shadow's nuts.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9916281700134277}]: Shadow just gets crazy.\n",
      "PRED [{'label': 'neutral', 'score': 0.8939750790596008}]: shadow 's nuts .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.7447255253791809}]: but it is an ancient right of losers to leave Starside and resort to ice empties.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999351501464844}]: 'However, it is the immemorial right of the fallen to quit Starside and forge for the Ice lands.\n",
      "PRED [{'label': 'neutral', 'score': 0.999958872795105}]: but it is an ancient right of poraments to leave Starside and resort to ice empties .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.7292569875717163}]: Get your finger off, Lars.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9990098476409912}]: put your finger away, Lars.\n",
      "PRED [{'label': 'toxic', 'score': 0.7956154942512512}]: Get your finger off , Lars .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9707499742507935}]: the fat officer rode over to Capel.\n",
      "GOLD [{'label': 'toxic', 'score': 0.9377005100250244}]: The fat officer moved alongside Capel.\n",
      "PRED [{'label': 'toxic', 'score': 0.9613781571388245}]: the fat officer rode over to Capel .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9964162111282349}]: Wash your brains also, \"King Kong!\n",
      "GOLD [{'label': 'neutral', 'score': 0.9998095631599426}]: I took your mind off of King Kong.\n",
      "PRED [{'label': 'toxic', 'score': 0.9884365797042847}]: Wash your brains also , `` King Kong !\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9963772892951965}]: Once I heard about this girl who picked up the phone and said “Hi, it’s Helen, and I want you to fuck me raw” because she was sure it was her boyfriend, only it turned out to be her father.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999351501464844}]: I heard about a girl who took the phone and said: \"Hello, this is Helena, and I want you to raise my soul from the body,\" because she was sure it was her boy, but it turned out her dad was calling her.\n",
      "PRED [{'label': 'toxic', 'score': 0.9035631418228149}]: Once I heard about this girl who picked up the phone and said “ Hi , it ’ s Helen , and I want you to screwing me raw ” because she was sure it was her boyfriend , only it turned out to be her father .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9968352913856506}]: You didn't fuck her once, you did it over and over, as though you wanted to get up inside her.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9999574422836304}]: you didn't push him into it, but again and again, as if you wanted to get into it.\n",
      "PRED [{'label': 'toxic', 'score': 0.9917562007904053}]: You did n't screwing her once , you did it over and over , as though you wanted to get up inside her .\n",
      "\n",
      "INIT [{'label': 'toxic', 'score': 0.9943100214004517}]: \"I see dumb people.\" was printed on t-shirts due to the excessive use of the original line.\n",
      "GOLD [{'label': 'neutral', 'score': 0.9998334646224976}]: \"I see mute people\" was printed on T-shirts for exaggerated use of the original phrase.\n",
      "PRED [{'label': 'neutral', 'score': 0.9993364214897156}]: `` I see mute people . '' was printed on t-shirts due to the excessive use of the original line .\n",
      "\n",
      "Success in 26 / 50 samples, i.e., turned the text into a neutral one. (No context preserving check!)\n"
     ]
    }
   ],
   "source": [
    "count_success = 0\n",
    "\n",
    "for _, row in random_test_data.iterrows():\n",
    "    ref_tokenized = tokenize_and_stem(row.reference, inference=True)\n",
    "    trn_tokenized = tokenize_and_stem(row.translation, inference=True)\n",
    "    if row.ref_tox < row.trn_tox:\n",
    "        ref_tokenized, trn_tokenized = trn_tokenized, ref_tokenized\n",
    "    \n",
    "    answer = []\n",
    "    for i in range(len(ref_tokenized)):\n",
    "        w = ref_tokenized[i]\n",
    "        if w in tox_dict:\n",
    "            answer.append(tox_dict[w])\n",
    "        else:\n",
    "            answer.append(w)\n",
    "    answer = ' '.join(answer)\n",
    "    \n",
    "    if row.ref_tox < row.trn_tox:\n",
    "        print(f'INIT {text_classifier(row.translation)}: {row.translation}')\n",
    "        print(f'GOLD {text_classifier(row.reference)}: {row.reference}')\n",
    "    else:\n",
    "        print(f'INIT {text_classifier(row.reference)}: {row.reference}')\n",
    "        print(f'GOLD {text_classifier(row.translation)}: {row.translation}')\n",
    "\n",
    "    answer_toxicity = text_classifier(answer)\n",
    "    count_success += answer_toxicity[0]['label'] == 'neutral'\n",
    "    print(f'PRED {answer_toxicity}: {answer}')\n",
    "    print()\n",
    "print(f'Success in {count_success} / {n} samples, i.e., turned the text into a neutral one. (No context preserving check!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic testing with text toxicity classifier:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic testing with text toxicity classifier: 100%|██████████| 5000/5000 [19:29<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in 2851 / 5000 samples (57.02), i.e., turned the text into a neutral one. (No context preserving check!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "count_success = 0\n",
    "random_test_data_auto = test_data.sample(n=5000, random_state=42)\n",
    "\n",
    "\n",
    "for _, row in tqdm(random_test_data_auto.iterrows(), desc='Automatic testing with text toxicity classifier', total=len(random_test_data_auto)):\n",
    "    ref_tokenized = tokenize_and_stem(row.reference, inference=True)\n",
    "    trn_tokenized = tokenize_and_stem(row.translation, inference=True)\n",
    "    if row.ref_tox < row.trn_tox:\n",
    "        ref_tokenized, trn_tokenized = trn_tokenized, ref_tokenized\n",
    "    \n",
    "    answer = []\n",
    "    for i in range(len(ref_tokenized)):\n",
    "        w = ref_tokenized[i]\n",
    "        if w in tox_dict:\n",
    "            answer.append(tox_dict[w])\n",
    "        else:\n",
    "            answer.append(w)\n",
    "    answer = ' '.join(answer)\n",
    "    answer_toxicity = text_classifier(answer)\n",
    "    count_success += answer_toxicity[0]['label'] == 'neutral'\n",
    "\n",
    "print(f'Success in {count_success} / {len(random_test_data_auto)} samples ({count_success / len(random_test_data_auto) * 100 :.2f}), i.e., turned the text into a neutral one. (No context preserving check!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, dictionary results in relatively small size (389 pairs). To increase its size, we need just take a bigger data sample for building it. As for metric that I used, this method got the result of 57.02% accuracy, which means more than half of samples were turned into neutral text (no meaning preserving check) successfully. \n",
    "\n",
    "As it is first try and simple straightforward solution it has low quality and many things can be improved. For example, we might consider to change building algorithm, take special corpora of toxic and neutral words and build a model that will choose the most closest neutral to replace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
