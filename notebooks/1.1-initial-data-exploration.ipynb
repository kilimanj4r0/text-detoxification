{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data should be downloaded, use 1.0-download-raw-data.ipynb notebook\n",
    "raw_data_path = '../data/raw/filtered.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(raw_data_path, sep='\\t', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights about data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are English data sample pairs <`text with high toxicity level`, `paraphrased text with low toxicity level`>. I will repeat for conveniece the description of the data columns below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column | Type | Discription | \n",
    "| ----- | ------- | ---------- |\n",
    "| reference | str | First item from the pair | \n",
    "| ref_tox | float | toxicity level of reference text | \n",
    "| translation | str | Second item from the pair - paraphrazed version of the reference|\n",
    "| trn_tox | float | toxicity level of translation text |\n",
    "| similarity | float | cosine similarity of the texts |\n",
    "| length_diff | float | relative length difference between texts |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 577777 entries, 0 to 577776\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   reference    577777 non-null  object \n",
      " 1   translation  577777 non-null  object \n",
      " 2   similarity   577777 non-null  float64\n",
      " 3   lenght_diff  577777 non-null  float64\n",
      " 4   ref_tox      577777 non-null  float64\n",
      " 5   trn_tox      577777 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 30.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>577777.000000</td>\n",
       "      <td>577777.000000</td>\n",
       "      <td>577777.000000</td>\n",
       "      <td>577777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.758469</td>\n",
       "      <td>0.157652</td>\n",
       "      <td>0.541372</td>\n",
       "      <td>0.434490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.092695</td>\n",
       "      <td>0.108057</td>\n",
       "      <td>0.457571</td>\n",
       "      <td>0.458904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.600001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.681105</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.754439</td>\n",
       "      <td>0.141791</td>\n",
       "      <td>0.806795</td>\n",
       "      <td>0.085133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.831244</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.990469</td>\n",
       "      <td>0.973739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.999730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          similarity    lenght_diff        ref_tox        trn_tox\n",
       "count  577777.000000  577777.000000  577777.000000  577777.000000\n",
       "mean        0.758469       0.157652       0.541372       0.434490\n",
       "std         0.092695       0.108057       0.457571       0.458904\n",
       "min         0.600001       0.000000       0.000033       0.000033\n",
       "25%         0.681105       0.066667       0.012171       0.000707\n",
       "50%         0.754439       0.141791       0.806795       0.085133\n",
       "75%         0.831244       0.238095       0.990469       0.973739\n",
       "max         0.950000       0.400000       0.999724       0.999730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference      If Alkar is flooding her with psychic waste, t...\n",
      "translation    if Alkar floods her with her mental waste, it ...\n",
      "similarity                                              0.785171\n",
      "lenght_diff                                             0.010309\n",
      "ref_tox                                                 0.014195\n",
      "trn_tox                                                 0.981983\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95, 96, 0.010526315789473717, True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding relative length difference feature\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sample = df.iloc[0]\n",
    "print(sample)\n",
    "length_diff = abs(1 - len(sample['translation']) / len(sample['reference']))\n",
    "len(sample['reference']), len(sample['translation']), length_diff, np.isclose(length_diff, sample['lenght_diff'], 1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to pandas `describe()` and given paper [[1]](https://arxiv.org/pdf/2109.08914.pdf): \n",
    "\n",
    "- To make the text more manageable for the model to process, we need to split `reference` and `translation` into smaller units called tokens (i.e., do tokenization step).\n",
    "- Toxicity level of reference and translation can be used as a numerical feature for the model. This level ranges between 0 and 1, where a value closer to 1 indicates more toxicity, and closer to 0 means less toxicity.\n",
    "- Similarity is computed as the cosine distance between the averaged BERT embeddings of all words in a sentence of the text. Similarity values fall between 0.6 and 0.95. Higher similarity values mean the texts are more alike, and when the similarity is 1, it means the texts are exactly the same. Can be used as a numerical feature for the model.\n",
    "- Relative length difference between text computed as a ratio between character length of reference and character length of translation. The maximum difference is 40%, and it can be used as a numerical feature for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish a baseline, we can start by creating a dictionary-based model that leverages the vocabulary from the provided dataset to replace highly toxic words. \n",
    "\n",
    "Next, we can combine all the numerical features with text representation embeddings. Custom embeddings could include all data features: `similarity`, `length_diff`, `ref_tox`, `reference`, `trn_tox`, and `translation`. To keep these elements organized, we can include separator tokens between the text embeddings and numerical features. This approach is applicable to various sequence-to-sequence models, such as RNNs, LSTMs, GRUs, or Transformers.\n",
    "\n",
    "Additionally, we can explore utilizing a pretrained Large Language Model (LLM) like GPT or Llama. Different techniques, such as zero-shot, few-shot, or in-context learning, can be applied to fine-tune the model for the task.\n",
    "\n",
    "In summary, we can pursue three main avenues for experimentation:\n",
    "1. dictionary-based approach\n",
    "2. sequence-to-sequence models\n",
    "3. pretrained LLMs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
