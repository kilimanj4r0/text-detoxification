{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to evaluate performance of the models. [As described](https://github.com/s-nlp/detox/tree/main#evaluation) in the [code of the given paper](https://github.com/s-nlp/detox/blob/main/emnlp2021/metric/metric.py), many different metrics are computing to access quality of the models. For simplicity, I will choose only some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define metric calculation funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def style_transfer_accuracy(preds, batch_size=32):\n",
    "    print('Calculating style of predictions')\n",
    "    results = []\n",
    "\n",
    "    classifier_model_name = 's-nlp/roberta_toxicity_classifier'\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(classifier_model_name)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(classifier_model_name)\n",
    "\n",
    "    for i in tqdm(range(0, len(preds), batch_size)):\n",
    "        batch = tokenizer(preds[i:i + batch_size], return_tensors='pt', padding=True)\n",
    "        with torch.inference_mode():\n",
    "            logits = model(**batch).logits\n",
    "        result = torch.softmax(logits, -1)[:, 1].cpu().numpy()\n",
    "        results.extend([1 - item for item in result])\n",
    "\n",
    "    accuracy = np.mean(results)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def bleu_score(inputs, preds):\n",
    "    bleu_sim = 0\n",
    "    counter = 0\n",
    "    print('Calculating BLEU similarity')\n",
    "    for i in tqdm(range(len(inputs))):\n",
    "        if len(inputs[i]) > 3 and len(preds[i]) > 3:\n",
    "            bleu_sim += sentence_bleu([inputs[i]], preds[i])\n",
    "            counter += 1\n",
    "\n",
    "    return float(bleu_sim / counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating style of predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style transfer accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sta = style_transfer_accuracy(['you are amazing'])\n",
    "print(f'Style transfer accuracy: {sta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1197.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlEU score: 0.4758733096412523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bleu = bleu_score(['you are fuck'], ['you are amazing'])\n",
    "print(f'BlEU score: {bleu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models' results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary based model\n",
    "\n",
    "Evaluation is inside 2.0-dictionary-based-model.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 Finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That is a perfect song.</td>\n",
       "      <td>What a fantastic song.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for God's sake!</td>\n",
       "      <td>Oh dear, please stop that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kadaj's group is young and violent.</td>\n",
       "      <td>Toxic text: Kadaj's gang is young and brutal.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is it about the two of you and your homosexual...</td>\n",
       "      <td>Is that about you two being intimate? Look.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I try not to murder.</td>\n",
       "      <td>I don't wish to harm you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0                            That is a perfect song.   \n",
       "1                                    for God's sake!   \n",
       "2                Kadaj's group is young and violent.   \n",
       "3  is it about the two of you and your homosexual...   \n",
       "4                               I try not to murder.   \n",
       "\n",
       "                                               preds  \n",
       "0                             What a fantastic song.  \n",
       "1                         Oh dear, please stop that.  \n",
       "2  Toxic text: Kadaj's gang is young and brutal.\\...  \n",
       "3        Is that about you two being intimate? Look.  \n",
       "4                          I don't wish to harm you.  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "outputs_directory = '../data/interim/model-outputs'\n",
    "dfs = []\n",
    "csv_files = [f for f in os.listdir(outputs_directory) if f.endswith('.csv')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(outputs_directory, csv_file)\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "    dfs.append(df)\n",
    "\n",
    "llm_result_df = pd.concat(dfs, ignore_index=True)\n",
    "llm_result_df.fillna('', inplace=True)  # Fill nan if exist\n",
    "llm_result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "llm_output_dir = '../data/interim/model-outputs/llm-mistral-10shots.csv'\n",
    "llm_result_df = pd.read_csv(llm_output_dir, index_col=0)\n",
    "llm_result_df.fillna('', inplace=True)  # Fill nan if exist\n",
    "llm_result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14687/14687 [00:04<00:00, 3058.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.2950518382909825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = list(llm_result_df['inputs'])\n",
    "preds = list(llm_result_df['preds'])\n",
    "bleu = bleu_score(inputs, preds)\n",
    "print(f'BLEU score: {bleu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta = style_transfer_accuracy(preds, batch_size=128)\n",
    "print()\n",
    "print(f'Style transfer accuracy: {sta}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vladimir-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
