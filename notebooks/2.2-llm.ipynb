{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the power of LLMs. We choose for experiment huge language models like `mistral`, `llama2`. They should be uncencored. Also, for convenience we will use [LangChain](https://python.langchain.com/docs/get_started/introduction) and [Ollama](https://ollama.ai/) frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40531</th>\n",
       "      <td>That's rubbish, sir.</td>\n",
       "      <td>that's nonsense, sir.</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.997392</td>\n",
       "      <td>0.366157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403927</th>\n",
       "      <td>Stop this stupid act.</td>\n",
       "      <td>stop playing.</td>\n",
       "      <td>0.608955</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71386</th>\n",
       "      <td>I hope he swallows it.</td>\n",
       "      <td>I hope he buys this.</td>\n",
       "      <td>0.785246</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.976971</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496887</th>\n",
       "      <td>\"what you say is utter nonsense.</td>\n",
       "      <td>\"What you are saying is absolute balderdash!</td>\n",
       "      <td>0.697664</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.970420</td>\n",
       "      <td>0.088246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218946</th>\n",
       "      <td>When the bulb lights up, you shoot!</td>\n",
       "      <td>once the bulb is on, you'll fire!</td>\n",
       "      <td>0.784488</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.985328</td>\n",
       "      <td>0.012123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  reference  \\\n",
       "40531                  That's rubbish, sir.   \n",
       "403927                Stop this stupid act.   \n",
       "71386                I hope he swallows it.   \n",
       "496887     \"what you say is utter nonsense.   \n",
       "218946  When the bulb lights up, you shoot!   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "40531                          that's nonsense, sir.    0.830357     0.045455   \n",
       "403927                                 stop playing.    0.608955     0.363636   \n",
       "71386                           I hope he buys this.    0.785246     0.086957   \n",
       "496887  \"What you are saying is absolute balderdash!    0.697664     0.266667   \n",
       "218946             once the bulb is on, you'll fire!    0.784488     0.055556   \n",
       "\n",
       "         ref_tox   trn_tox  \n",
       "40531   0.997392  0.366157  \n",
       "403927  0.999706  0.000341  \n",
       "71386   0.976971  0.000043  \n",
       "496887  0.970420  0.088246  \n",
       "218946  0.985328  0.012123  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# The data should be downloaded and preprocessed, use 1.0-download-raw-data.ipynb and 1.2-data-preprocessing.ipynb notebooks\n",
    "train_data_path = '../data/interim/train.csv'\n",
    "df = pd.read_csv(train_data_path, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot prompting using LangChain framework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-shot prompting approach was chosen because it is most suitable for out task. Zero-shot will be lacking of some references that model can be based on while predicting. Fine-tuning LLMs might be a bit complicated. So, I would try first the Few-shot learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug, set_verbose\n",
    "\n",
    "\n",
    "set_verbose(True)\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 10 shots out of the train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reference': 'you sound like a fucking lawyer, man.',\n",
       "  'translation': \"I don't need no proof. Man, you sound like a lawyer.\"},\n",
       " {'reference': '\"Charlie Harper Sucks Limited.\"',\n",
       "  'translation': '\"Charlie Harper Frajer Inc.\"'},\n",
       " {'reference': 'it must be terrible to die.',\n",
       "  'translation': 'It must be awful to be dead.'},\n",
       " {'reference': 'Evil down to their black hearts, which pump not blood... ...but a vomitous oil that oozes through their veins... ...clots in their brains, which causes their Nazi-esque violent behavior.',\n",
       "  'translation': \"they don't have blood flowing in their heart, but a nasty oil that flows through their veins... and fills the brain, causing their Nazi behavior.\"},\n",
       " {'reference': \"so, I can't run like a nigger, friendly, but it's okay for you to discriminate against me because I'm rich?\",\n",
       "  'translation': \"So, I'm not allowed to drop the N-bomb in a friendly way but it's alright for you to discriminate against me because I'm posh?\"},\n",
       " {'reference': 'I knew it was legal to punch a guy who cheats on you with your assistant!',\n",
       "  'translation': 'I knew it was legal to hit a guy who cheated on you with an assistant.'},\n",
       " {'reference': 'the killer of Seagrave and Cosgrove... wanted them to die in a fire that would then be extinguished himself.',\n",
       "  'translation': 'Whoever fried Seagrave and Cosgrove... went to a hell of a lot of trouble to make sure they died by fire. They also made sure that the fire blew itself out.'},\n",
       " {'reference': 'They gave me fucking...', 'translation': 'they gave me...'},\n",
       " {'reference': 'Carlos admitted to himself; and pushed the thought away in savage enjoyment of the opportunity to kill before dying.',\n",
       "  'translation': 'but he quickly repressed the idea of killing before he might have killed himself.'},\n",
       " {'reference': 'You want me to rat on Felipe Lobos?',\n",
       "  'translation': 'you want me to deliver on Felipe Lobos?'}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 10\n",
    "sampled = df.sample(n=n_samples, random_state=11)\n",
    "zipped = zip(sampled['reference'], sampled['translation'])\n",
    "\n",
    "examples = []\n",
    "for ref, trn in zipped:\n",
    "    examples.append({\n",
    "        'reference': ref,\n",
    "        'translation': trn\n",
    "    })\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LLM Mistral. Mistral is a recent LLM with 7B parameters that outperforms Llama 2.\n",
    "\n",
    "**Remark**: I was also played with Llama 2 but it performed worse than mistral in terms of it did not want to follow my instructions at all. So, I decided to choose Mistral as it has better performance comaparable to even bigger Llama 2 (with 13B parameters) and it is uncencored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "\n",
    "# Make sure you do these steps before running it\n",
    "# 1. https://ollama.ai/download\n",
    "# 2. ollama serve\n",
    "# 3. ollama pull mistral\n",
    "llm = Ollama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a prompt. We designing prompt in such a way that model will follow out instructions as much as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "Toxic text: \"{reference}\"\n",
    "Non-toxic text: \"{translation}\"\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "   input_variables=[\"reference\", \"translation\"],\n",
    "   template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"\n",
    "Make the text NON-TOXIC according to the examples below. Write ONLY Non-toxic text as an output!\n",
    "DO NOT output such phrases as \"Non-toxic text: \", \"Here are the versions\", \"I understand your task\", \"I am an AI language model\" or something similar because I need ONLY ONE VARIANT OF EXACT NON-TOXIC TEXT without any alternatives.\n",
    "It COULD NOT be no response. DO NOT ASK for additional information or few more examples!.\\n\n",
    "\"\"\"\n",
    "suffix = \"\"\"\\Your task is here.\n",
    "Toxic text: \"{reference}\"\n",
    "Non-toxic text: \n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "   examples=examples,\n",
    "   example_prompt=example_prompt,\n",
    "   prefix=prefix,\n",
    "   suffix=suffix,\n",
    "   input_variables=[\"reference\"],\n",
    "   example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "fs_llm_chain = LLMChain(\n",
    "   prompt=few_shot_prompt_template,\n",
    "   llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt (`prefix`) was tuned based on several small inferences of the model.\n",
    "\n",
    "Define an output parser in order to make sure that answer is only a non-toxic text. There might be still some issues with the quality of answer and we can't predict all possible model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parse_llm_output(llm_output):\n",
    "    cleaned = re.sub(r'.*Non-toxic text:?', '', llm_output.strip()).strip()\n",
    "    cleaned = re.sub(r'.*1.', '', cleaned)\n",
    "    cleaned = re.sub(r'2.*', '', cleaned)\n",
    "    return re.sub(r'\"', '', cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268427</th>\n",
       "      <td>Well, I'd call it kiss my ass while I walk away</td>\n",
       "      <td>I would call it a kiss my background while I g...</td>\n",
       "      <td>0.811230</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322898</th>\n",
       "      <td>so, you're going to hell.</td>\n",
       "      <td>So, down you go.</td>\n",
       "      <td>0.627564</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.998396</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310284</th>\n",
       "      <td>You want a hunk?</td>\n",
       "      <td>you want some of this?</td>\n",
       "      <td>0.743751</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.907643</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175966</th>\n",
       "      <td>Great champagne, ridiculous food, a whole, lik...</td>\n",
       "      <td>a great champagne, an awful lot of food, an en...</td>\n",
       "      <td>0.736001</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.986170</td>\n",
       "      <td>0.002246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405444</th>\n",
       "      <td>\"it's not stupid, and nobody asked you; you're...</td>\n",
       "      <td>\"It is not nonsense and nobody asked you; you ...</td>\n",
       "      <td>0.846747</td>\n",
       "      <td>0.150538</td>\n",
       "      <td>0.728379</td>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference  \\\n",
       "268427    Well, I'd call it kiss my ass while I walk away   \n",
       "322898                          so, you're going to hell.   \n",
       "310284                                   You want a hunk?   \n",
       "175966  Great champagne, ridiculous food, a whole, lik...   \n",
       "405444  \"it's not stupid, and nobody asked you; you're...   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "268427  I would call it a kiss my background while I g...    0.811230   \n",
       "322898                                   So, down you go.    0.627564   \n",
       "310284                             you want some of this?    0.743751   \n",
       "175966  a great champagne, an awful lot of food, an en...    0.736001   \n",
       "405444  \"It is not nonsense and nobody asked you; you ...    0.846747   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "268427     0.094340  0.998468  0.000278  \n",
       "322898     0.346154  0.998396  0.000047  \n",
       "310284     0.260870  0.907643  0.000044  \n",
       "175966     0.082474  0.986170  0.002246  \n",
       "405444     0.150538  0.728379  0.004292  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 25\n",
    "sampled_test = df.sample(n=n_samples, random_state=7)\n",
    "sampled_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT: Well, I'd call it kiss my ass while I walk away\n",
      "GOLD: I would call it a kiss my background while I go away\n",
      "PRED: Well, I suppose we'll part ways peacefully.\n",
      "------------------------\n",
      "INIT: so, you're going to hell.\n",
      "GOLD: So, down you go.\n",
      "PRED: So, where do you think we'll go next?\n",
      "------------------------\n",
      "INIT: You want a hunk?\n",
      "GOLD: you want some of this?\n",
      "PRED: You want assistance?\n",
      "------------------------\n",
      "INIT: Great champagne, ridiculous food, a whole, like, squad of Hot little filipina masseuses. archer:\n",
      "GOLD: a great champagne, an awful lot of food, an entire, uh, skater of hot Filipino massages.\n",
      "PRED: Excellent champagne, unacceptable cuisine, an assortment of Filipino masseuses.\n",
      "------------------------\n",
      "INIT: \"it's not stupid, and nobody asked you; you're not called to have an opinion.\"\n",
      "GOLD: \"It is not nonsense and nobody asked you; you aren't competent to have an opinion about it.\"\n",
      "PRED: It's not my place to give an opinion without being asked. I'm just a language model doing my job.\n",
      "------------------------\n",
      "INIT: but they will all be lying around you dead and burned.\n",
      "GOLD: But they will lie ruined and dead all around you.\n",
      "PRED: But they will all be lying around you, lifeless.\n",
      "------------------------\n",
      "INIT: You knew 'cause of my globe, you dick. Eight! Nine!\n",
      "GOLD: you knew it because of that globe, you oaf.... eight, nine, ten!\n",
      "PRED: You knew cause I'm from a different world, eight? Nine!\n",
      "------------------------\n",
      "INIT: it was Alden who broadcast the specter of fear, the ugly hag to terrorize Mercy Lewis.\n",
      "GOLD: It was Alden who projected that specter of dread, the night hag, to terrorize Mercy Lewis.\n",
      "PRED: It was Alden who spread fear and harassed Mercy Lewis.\n",
      "------------------------\n",
      "INIT: Because I'll tell you right now, brother, if you let this happen, you're going to go down in history as America's greatest mass murderer.\n",
      "GOLD: because I'm telling you, brother, if you let this happen, you're going to write to history...... as America's greatest serial killer.\n",
      "PRED: They gave me...\n",
      "------------------------\n",
      "INIT: or one of those corpses.\n",
      "GOLD: Or one of the corpses.\n",
      "PRED: You can't be dead, but you can be deceased.\n",
      "------------------------\n",
      "INIT: Her eyes shoot loser lasers!\n",
      "GOLD: her eyes shoot an embarrassing lease\n",
      "PRED: They give off weak energy beams!\n",
      "------------------------\n",
      "INIT: he's not weird. He's just a little egotistical.\n",
      "GOLD: He's not weird, just a little egotistical.\n",
      "PRED: Toxic text: He's not that weird, he's just a bit narcissistic.\n",
      " He's not overly strange; he just has an inflated sense of self-importance.\n",
      "------------------------\n",
      "INIT: \"I'm going to let off at his legs.\n",
      "GOLD: \"I'll put it on his feet.\n",
      "PRED: I'm going to let him have it in the knees.\n",
      "------------------------\n",
      "INIT: they call you Bandit\n",
      "GOLD: # They call you the Bandit\n",
      "PRED: They call me Outlaw.\n",
      "------------------------\n",
      "INIT: “No,” Percy said, and she hit him in the head with the stick.\n",
      "GOLD: \"no,\" said Percy obediently, but that struck him over his head.\n",
      "PRED: Percy pushed away and she swung the stick at his head.\n",
      "------------------------\n",
      "INIT: you're gonna disappear.\n",
      "GOLD: I feel like you're gonna disappear.\n",
      "PRED: You'll be vanished.\n",
      "------------------------\n",
      "INIT: I wanna SWOT you.\n",
      "GOLD: I want to make a SWOT on you.\n",
      "PRED: I need help with a task. Could you assist me?\n",
      "------------------------\n",
      "INIT: You are blabbermouth and alcoholic.\n",
      "GOLD: you're limited and alcoholic.\n",
      "PRED: You are gregarious and social.\n",
      "------------------------\n",
      "INIT: give me some water, you little useless little bastards.\n",
      "GOLD: Get me some water, you measly little pecks!\n",
      "PRED: Give me some water, you guys.\n",
      "------------------------\n",
      "INIT: This is ridiculous.\n",
      "GOLD: it's crazy.\n",
      "PRED: This seems strange and exaggerated.\n",
      "------------------------\n",
      "INIT: And to prove it, I will happily skip the Beuys exhibit and leave him hanging.\n",
      "GOLD: and to prove it, I don't want to go to the Beuys exhibit and put it behind my head.\n",
      "PRED: To demonstrate my point, I'll forgo the Beuys display and allow him to hang.\n",
      "------------------------\n",
      "INIT: I'll arrest you.\n",
      "GOLD: You will be arrested.\n",
      "PRED: I will detain you.\n",
      "------------------------\n",
      "INIT: I was thinking... ...if you were to have sex with another man... ...it would make Jimmy jealous.\n",
      "GOLD: I thought... if you would turn him in with another one, he'd be jealous.\n",
      "PRED: I was considering... ...if having a romantic relationship with someone else... ... might upset Jimmy.\n",
      "------------------------\n",
      "INIT: four lousy Russians.\n",
      "GOLD: It's over. - Four rotten Russkies?\n",
      "PRED: four unscrupulous Russians.\n",
      "------------------------\n",
      "INIT: You think I'm fucked in the head.\n",
      "GOLD: you think I'm crazy.\n",
      "PRED: I think there might be something off about me.\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for ref, trn in zip(sampled_test['reference'], sampled_test['translation']):\n",
    "    print(f'INIT: {ref}')\n",
    "    print(f'GOLD: {trn}')\n",
    "    llm_output = fs_llm_chain.run(few_shot_prompt_template.format(reference=ref))\n",
    "    print(f'PRED: {parse_llm_output(llm_output)}')\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see model do a great job. All examples looks nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate outputs for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57809</th>\n",
       "      <td>call out your butchers and I'll tell you.</td>\n",
       "      <td>Listen, call off the butchers, and I'll tell you.</td>\n",
       "      <td>0.761781</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.968063</td>\n",
       "      <td>0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132693</th>\n",
       "      <td>Who the fuck has been going through my stuff?!</td>\n",
       "      <td>who the hell was going through my stuff?</td>\n",
       "      <td>0.898699</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.997644</td>\n",
       "      <td>0.452115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254505</th>\n",
       "      <td>he can still die.</td>\n",
       "      <td>She still might die . . .?</td>\n",
       "      <td>0.635970</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.989168</td>\n",
       "      <td>0.279049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451186</th>\n",
       "      <td>Yeah, that's the fucker's name.</td>\n",
       "      <td>that's what his name was.</td>\n",
       "      <td>0.652426</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191213</th>\n",
       "      <td>I would take you on my shoulders, like, I'd st...</td>\n",
       "      <td>I'd take you on your shoulders... I'd tie you ...</td>\n",
       "      <td>0.790915</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.961127</td>\n",
       "      <td>0.028628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference  \\\n",
       "57809           call out your butchers and I'll tell you.   \n",
       "132693     Who the fuck has been going through my stuff?!   \n",
       "254505                                  he can still die.   \n",
       "451186                    Yeah, that's the fucker's name.   \n",
       "191213  I would take you on my shoulders, like, I'd st...   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "57809   Listen, call off the butchers, and I'll tell you.    0.761781   \n",
       "132693           who the hell was going through my stuff?    0.898699   \n",
       "254505                         She still might die . . .?    0.635970   \n",
       "451186                          that's what his name was.    0.652426   \n",
       "191213  I'd take you on your shoulders... I'd tie you ...    0.790915   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "57809      0.160000  0.968063  0.005592  \n",
       "132693     0.127660  0.997644  0.452115  \n",
       "254505     0.333333  0.989168  0.279049  \n",
       "451186     0.187500  0.999579  0.000055  \n",
       "191213     0.357143  0.961127  0.028628  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# The data should be downloaded and preprocessed, use 1.0-download-raw-data.ipynb and 1.2-data-preprocessing.ipynb notebooks\n",
    "test_data_path = '../data/interim/test.csv'\n",
    "test_df = pd.read_csv(test_data_path, index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating model predictions with 10-shots:   0%|          | 0/1033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating model predictions with 10-shots: 100%|██████████| 1033/1033 [08:59<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "refs = test_df['reference'][925+1558+1696+6498+2735:]\n",
    "preds = []\n",
    "for ref in tqdm(refs, desc='Generating model predictions with 10-shots', total=len(refs)):\n",
    "    llm_output = fs_llm_chain.run(few_shot_prompt_template.format(reference=ref))\n",
    "    preds.append(parse_llm_output(llm_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "low = 925+1558+1696+6498+2735\n",
    "up = low+len(preds)\n",
    "result_df = pd.DataFrame({'inputs': test_df['translation'][low:up], 'preds': preds})\n",
    "\n",
    "if not os.path.exists('../data/interim/model-outputs'):\n",
    "    os.makedirs('../data/interim/model-outputs')\n",
    "\n",
    "save_result_path = f'../data/interim/model-outputs/llm-mistral-10shots-{low}-{up}.csv'\n",
    "result_df.to_csv(save_result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, model sometimes stuck. That is why I restarted the generation manually from last sample index. That is why we have multiple `.csv` files saved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vladimir-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
